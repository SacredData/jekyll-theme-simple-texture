---
layout: post
title: "A Brief Introduction"
description: "A Sonic Multiplicities overview."
categories: [general]
tags: []
redirect_from:
  - /2017/12/14/
---

* Kramdown table of contents
{:toc .toc}

# Introduction to Sonic Multiplicities

My saga began in 2008, the year I began my education at the Jacobs School of Music. I developed Sonic Multiplicities independently, choosing to not build on top of other electroacoustic methodologies being explored at the time throughout academia. I was disappointed when I left my bedroom for one of the world's finest music institutions to encounter uninspiring, derivative approaches such as the "laptop orchestra"[^1].

Composers utilizing electronics in the early 20th century can be credited with introducing brand new musical languages to the concert hall. But since computer technology became the main tool of the electroacoustic composer, the results have been largely stale and stagnant. Computers did more to automate and streamline traditional compositional processes, and less to broaden the size and scope of the sonic pallette. Though great works have been conceived on highly specialized and proprietary audio delivery formats such as higher-order ambisonic arrays, the accessibility of such approaches is limited. Generally, the latter half of the 20th century as a whole can be seen as in decline, compared with the former half, as it relates to innovations in electronic music.

To me, modern electroacoustic music still has not solved certain essential challenges:
* Unnatural, musically-clumsy input methodology
* Inability to modulate rhythm/tempi gracefully
* Very poor stage appeal ("is the laptop performer running a Max patch or checking their email?")

As both a composer and a media technologist, I have observed many novel approaches to solve these issues, notably on the musical computer input front. Leveraging MIDI controllers, OSC signals, DIY hardware, and other such things, I have seen many a musical peer attempt to construct a musical language on top of proprietary audio software like Ableton Live. The problem with these approaches is the limitation they place upon the performer and composer alike. Pre-fabbed audio software wrestles control away from the composer by making highly opinionated choices around interface design, audio routing, and other essential properties. Similarly, performers are restricted by having to retrofit largely un-musical inputs into the larger corporate digital music paradigm.

Modern computing technology is so powerful that its users should not have to compromise musical integrity just to leverage it. Musicians are taught a timeless, highly skilled art that should not have to be devalued, simplified, or minimized, especially when paired with a technology so easily adopted. Followingly, if a composer chooses to utilize modern digital audio technology to achieve their aesthetic goals, they ought to be well-enough versed in the computer sciences to implement their own software and tools. Otherwise, both their performers and their audiences will be subjected to the very musical compromises that have caused electroacoustic music to become largely stagnant.

## Musical Input

As a novice seven-year-old drummer, I started out on a three-piece drum kit: bass, snare, high tom, hi-hat, and crash cymbal. My instructor explained that all those extra fancy toms, cymbals, and miscellaneous doodads were super cool, but why bother playing them until you can master a three-piece kit first? What advantage could you take of extra pieces if you could not fully exploit a simpler kit?

Input into Sonic Multiplicities is musical, and simple. The system takes one - and only one - microphone input, meant to be used by a single, solo instrumentalist. I see no need to process more than one musical input, because as of today, Sonic Multiplicities is still very much an experimental methodology. Why add more inputs before mastering solo input?

## Logic-Based Compositional Framework

As a composer, I wanted to present a new type of compositional structure, which would define a system of rules, triggers, possibilities, and aleatoric contexts.

An SM piece is composed through the following actions:
* Tuning the AI stack's _weights and measures_
* Designing a series of _triggers_, which invoke changes to either the internal systemic logic, or the sonic output of the SM software
* Defining a series of _synths_, which process the input signal and/or stored audio buffers deriving from prior input signals
* Defining a series of _rhythmic patterns, subpatterns, and subdivisions_, which may process the input signal or other internally-generated audio signals
* Constructing one or more _musical routines_, which serve as the gestural and melodic theme(s) of the work

Sonic Multiplcities was originally conceived with opinionated logic, simply representing my personal opinions on what should happen when certain musical events occur during the performance. I have since taken these opinions out of the overall software framework, allowing each user to define their own schemas, leading to more personalized and experimental outcomes. Training the system on these outcomes creates a highly personalized SM context, making each SM node unique to its primary user(s).

### Logical Modifiers

In addition to the above-listed compositional actions, further variation and aleatory may be explored by inputting a JSON data object, and mapping its keys/values to certain properties as defined in the work. This introduces the potential for variation of outcome dependent upon date, time, location, weather, the Bitcoin/USD exchange rate, etc. Whatever strikes your fancy!

The system is further tuned by the virtuosity of the in-use audio equipment. High-end microphone/DSP interfaces, low-latency OS kernels, and proper mic technique enable tighter response times as well as more rhythmic accuracy. Lower-end and intentionally-misconfigured equipment, conversely, result in a less careful system, which deprioritizes accuracy in favor of stability and reduction of xruns.[^2] This dynamic approach to logic and modeling empowers composers to consider equipment selection and configuration artistically, rather than practically.

## Sonically-Multiplied Output

SM environments are rhythmically controlled through one or more TempoClocks. These TempoClocks may either be pre-determined or dynamically assigned. All signals generated by the software are tied to one of these TempoClocks, and it is through these rhythmic differences that the software distinguishes its own output from the sounds coming from the input itself. In this sense, it takes on its own life and musical meaning. It is both directed by, and through-inspires, the instrumentalist.


[^1]: [The "missionary position" of electronic music ensembles](https://i.ytimg.com/vi/RoH9ssraNtU/maxresdefault.jpg)
[^2]: [xruns should be avoided at all costs](https://alsa.opensrc.org/Xruns)
